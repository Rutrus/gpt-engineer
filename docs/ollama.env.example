# Configuration for using Ollama with GPT Engineer
# Copy this file to .env and adjust according to your needs

# Ollama API base URL
OPENAI_API_BASE=http://localhost:11434/v1

# API key (any value, Ollama doesn't require a real key)
OPENAI_API_KEY=ollama

# Model name to use
MODEL_NAME=qwen2.5-coder

# Explicitly enable Ollama integration
IS_OLLAMA=true

# Optional: Additional configuration
# LOCAL_MODEL=true
# TEMPERATURE=0.1